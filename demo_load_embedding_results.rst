How to load samples generated by fasseg_analysis
================================================

The script ``fasseg_analysis.py`` generates concept output masks for a
given set of sample images. This is a demo of the format and how to load
them.

Preparations
------------

First ensure that the external library is in the ``PYTHONPATH``:

>>> import sys, os
>>> sys.path.insert(0, os.path.join('sources', 'concept_analysis', 'ext_lib'))
>>> from sources.concept_analysis import ilp_samples

Specify the paths to both the results and the original data. Both should
contain the ``pos`` and ``neg`` folder with the images in the case of
``dataset_root`` and the .npz files in case of the ``results_root``.

>>> results_root = os.path.join("experiments", "ilp_samples",
                                "alexnet_2020-05-17_221047511878")  # just some example
>>> assert os.path.exists(results_root)
>>> # the root directory of the picasso data used to generate the .npz files
>>> dataset_root = os.path.join(project_root, "dataset", "picasso_dataset", "test")
>>> assert os.path.exists(dataset_root)

Load predictions
----------------

Now one can load the predictions and masks. Each ``<filename>.npz`` file
in the results_root sub-folders holds the following information about
``<filename>.png`` in the corresponding dataset_root location. When
loaded, it provides a dict-like with the following entries:

- ``pred``: the prediction of the main model as numpy array;
  to turn it into a truth value/class prediction, apply a sigmoid
  and threshold by 0.5, then <0.5 means negative class,
  and >0.5 means positive class
- ``MOUTH``, ``NOSE``, ``EYES``: the mask predicted for the corresponding
  part with values in [0,1];
  to obtain a binary mask, threshold at 0.5;
  the masks are of different scale than the image and need to be
  resized before comparison

>>> results = ilp_samples.load(results_root, gt_class_dirs=('pos', 'neg'))
Loading class pos: 100%|██████████| ...
Loading class neg: 100%|██████████| ...
>>> print(results)  # show the DataFrame
...


Take subsets of the predictions
-------------------------------

Example on selecting the samples predicted to be positive
(one can then assess length etc.):

>>> pos_pred = results[results.pred > 0.5]
>>> neg_pred = results[results.pred <= 0.5]
>>> print(len(pos_pred), ",", len(neg_pred))
50 , 50

Example on selecting false positives:

>>> fp = results[(results.pred > 0.5) & (results.ground_truth == 'neg')]
>>> fn = results[(results.pred <= 0.5) & (results.ground_truth == 'pos')]
>>> print(len(fp), ",", len(fn))
...

Having a look at the distribution of the predictions with respect to the
decision boundary:

>>> import matplotlib.pyplot as plt
>>> from matplotlib.ticker import MaxNLocator
>>> dist_to_border = results['pred']-0.5
>>> ax1 = dist_to_border.loc[dist_to_border.abs().sort_values()[:int(0.2*len(results))].index].hist(bins=20);
>>> ax1.set_title("Signed distances to decision boundary for 20% lowest values")
>>> ax1.yaxis.set_major_locator(MaxNLocator(integer=True))
>>> plt.show()
...
>>> ax2 = dist_to_border.loc[dist_to_border.abs().sort_values()[:int(0.2*len(results))].index].abs().hist(bins=20);
>>> ax2.yaxis.set_major_locator(MaxNLocator(integer=True));
>>> ax2.set_title("Distances to decision boundary for 20% lowest values");


Visualize results
-----------------

Now one can visualize the results with the following color code:

>>> mask_colors =
>>>     'EYES': 'red',
>>>     'NOSE': 'green',
>>>     'MOUTH': 'blue'
>>> }


Helper functions
~~~~~~~~~~~~~~~~

>>> from hybrid_learning.datasets import apply_mask
>>> from PIL import Image
>>> def display_samples(results, title: str = "", max_num_samples: int = 10, dpi=50):
...     num_samples = min(max_num_samples, len(results))
...     fig = plt.figure(figsize=(3*4, 3*num_samples), dpi=dpi)
...     axes = fig.subplots(num_samples, 4, sharey='row', squeeze=False)
...     fig.tight_layout(pad=2, rect=[0, 0.03, 1, 0.96])
...     fig.suptitle(title)
...     for row, result in [(i, results.iloc[i]) for i in range(num_samples)]:
...         img = Image.open(os.path.join(dataset_root, result.img_fp))
...         axes[row, 0].imshow(img)
...         axes[row, 0].set_xticks([])
...         axes[row, 0].set_yticks([])
...         axes[row, 0].set_title("pred {:.4}".format(result.pred))
...         for fig_col, (part, color) in enumerate(mask_colors.items()):
...             axes[row, fig_col+1].set_title(part)
...             mask = result[part].resize(img.size, resample=Image.BILINEAR)
...             axes[row, fig_col+1].imshow(apply_mask(img, mask, alpha=0.8, color=color))
...             axes[row, fig_col+1].set_xticks([])
...             axes[row, fig_col+1].set_yticks([])
>>>
>>> def display_samples_side_by_side(results, title: str = "", max_num_samples: int = 10, dpi=50):
...     num_samples = min(max_num_samples, len(results))
...     fig = plt.figure(figsize=(1.5*num_samples, 1.5), dpi=dpi)
...     axes = fig.subplots(1, num_samples, sharey='row')
...     axes[0].set_ylabel(title)
...     for col, result in [(i, results.iloc[i]) for i in range(num_samples)]:
...         img = Image.open(os.path.join(dataset_root, result.img_fp))
...         # add the masks for the concepts:
...         for part, color in mask_colors.items():
...             part_mask = result[part].resize(img.size, resample=Image.BILINEAR)
...             img = apply_mask(img, part_mask, alpha=0.8, color=color)
...         axes[col].imshow(img)
...         axes[col].set_xticks([])
...         axes[col].set_yticks([])


Visualization
~~~~~~~~~~~~~

Some samples for each ground truth class:

>>> num_samples = 3
>>> for gt_class in results.ground_truth.unique():
...     display_samples_side_by_side(results[results.ground_truth == gt_class].sample(4),
...                                  title="Class {}".format(gt_class), dpi=100)
...

Again some examples for each ground truth class, only this time
side-by-side:

>>> import pandas as pd
>>> display_samples_side_by_side(pd.concat([results[results.ground_truth == gt_class].sample(2)
...                                             for gt_class in results.ground_truth.unique()]),
...                              title="AlexNet".format(gt_class), dpi=600)
...

Again some samples for each ground truth class, now with each part
separately shown:

>>> num_samples = 3
>>> for gt_class in results.ground_truth.unique():
...     display_samples(results[results.ground_truth == gt_class].sample(num_samples),
...                     title="Ground Truth class {}".format(gt_class))
...

Some samples predicted positive and some predicted negative:
>>> display_samples(pos_pred.sample(num_samples), title="Positively predicted samples")
>>> display_samples(neg_pred.sample(num_samples), title="Negatively predicted samples")
...
